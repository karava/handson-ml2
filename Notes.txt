Completed:
* Review of chapter 1 notebook
* Quietly answered ch1 qts
* Review of chapter 2 notebook
* Review of chapter 2 exercises
    - generally quite difficult at the time and had little understanding
* Review of chapter 3 notebook
* Attempted Chapter 3 exercises
    - [TODO] Q1 Mnist choosing a model - ran on 6,000 (~30mins) instead of 60,000 (timed out) for the sake of time. Run on 60,000 to see how the results vary with more data and see if can get to the 97% number.
    - [TODO] Q2 Data augmentation - TD run data augmentation on 6,000 to see what the difference in results was. Note that because we do 4 augmentations, this multiplies the time for the entire 
    - [TODO] Titanic dataset - consider running on Kaggle kernel. Or run locally and compare.
    - [TODO] Clean notebooks have two notebooks for the exercises
    - [TODO] Report test set accuracy in the above so I have a single number estimator - use random seed if required.
    


Learnings:
* Always try to get a feel for the computation time, and try to start with smaller sample sizes if possible, record time. Then scale up.
* Move to a server or another machine if required - make this process easy aswell, perhaps have one dedicated crunching machine.
* Probably smart not to run computation on your laptop at all. Machine gets too hot and makes too much noise.